# -*- coding: utf-8 -*-
"""full.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZSqz1td6vTKiPDghzVzkpHuU3cZwnYlD
"""

import pandas as pd
import os
import time
ratings_filename = 'train.csv'


df_ratings = pd.read_csv(ratings_filename,
    usecols=['userId', 'movieId', 'rating'],
    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})

df_movie_features = df_ratings.pivot(
    index='userId',
    columns='movieId',
    values='rating'
).fillna(0)

df_movie_features

ratings_filename_test = 'test.csv'


df_ratings_test = pd.read_csv(ratings_filename_test,
    usecols=['userId', 'movieId', 'rating'],
    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})

df_movie_features_test = df_ratings_test.pivot(
    index='userId',
    columns='movieId',
    values='rating'
).fillna(0)

df_movie_features_test

df_ratings_test[~df_ratings_test.movieId.isin(df_ratings.movieId)]

df_ratings_test[~df_ratings_test.userId.isin(df_ratings.userId)]

import numpy as np
import math

K=50
alpha=0.01
beta = 0.001
R = np.array(df_movie_features)
latent_dim = K
iterations = 20
num_users, num_items = R.shape
P=np.random.normal(scale=1./latent_dim, size=(num_users, latent_dim))
Q=np.random.normal(scale=1./latent_dim, size=(num_items, latent_dim))
b_u = np.zeros(num_users)
b_i = np.zeros(num_items)
b = np.mean(R[np.where(R != 0)])
samples = [
    (i, j, R[i, j])
    for i in range(num_users)
    for j in range(num_items)
    if R[i, j] > 0
]


def train():
    for i in range(iterations):
        np.random.shuffle(samples)
        sgd()
        losss = mse()
        print("Iteration = ", i, ", losses=", losss)

def mse():
    xs, ys = R.nonzero()
    predicted = full_matrix()
    error = 0
    counter=0
    for x, y in zip(xs, ys):
        error += pow(R[x, y] - predicted[x, y], 2)
        counter+=1
    return np.sqrt(error/counter)

def sgd():
    for i, j, r in samples:
        prediction = get_rating(i, j)
        if math.isnan(prediction):
          get_rating_with_print(i,j)
          break
        e = (r - prediction)

        b_u[i] += alpha * (e - beta * b_u[i])
        b_i[j] += alpha * (e - beta * b_i[j])

        P[i, :] += alpha * (e * Q[j, :] - beta * P[i,:])
        Q[j, :] += alpha * (e * P[i, :] - beta * Q[j,:])

def get_rating(i, j):
    return b + b_u[i] + b_i[j] + P[i, :].dot(Q[j, :].T)

def full_matrix():
    return b + b_u[:,np.newaxis] + b_i[np.newaxis:,] + P.dot(Q.T)


begin_time_camputing_mf = time.time()
print(begin_time_camputing_mf)
train()
time_computing_mf = time.time() - begin_time_camputing_mf
print(time_computing_mf)

preds_df = pd.DataFrame(full_matrix())

preds_df.to_pickle("model")

preds_df = pd.read_pickle("model")

def recommend_movies(preds_df, userID, original_ratings_df, num_recommendations=5):
  pred_df = pd.DataFrame(np.array(preds_df), columns=df_movie_features.columns)
  sorted_user_predictions = (pred_df.iloc[userID-1].sort_values(ascending=False))
  user_data = original_ratings_df[original_ratings_df.userId == (userID)]
  return (pd.DataFrame(sorted_user_predictions.drop(user_data.movieId))[0:num_recommendations] / pd.DataFrame(sorted_user_predictions.drop(user_data.movieId)).max() * 4)


begin_recommend_time_mf = time.time()
print("recomendation for user", pd.unique(df_ratings_test.userId)[280])
print(recommend_movies(preds_df, pd.unique(df_ratings_test.userId)[280], df_ratings, 20))
recommend_time_mf = time.time() - begin_recommend_time_mf
print(recommend_time_mf)

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch
import pandas as pd

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

epochs = 100
batch_sz = 128

df_ratings = pd.read_csv("train.csv", usecols=['userId', 'movieId', 'rating'],
                         dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})

users = df_ratings['userId'].values - 1
movies = df_ratings['movieId'].values - 1
rates = df_ratings['rating'].values
n_samples = len(rates)

n_users, n_movies =  max(users)+1, max(movies)+1
batches = []
batch_sz = 128


for i in range(0, n_samples, batch_sz):
  limit =  min(i + batch_sz, n_samples)
  users_batch, movies_batch, rates_batch = users[i: limit], movies[i: limit], rates[i: limit]
  batches.append((torch.tensor(users_batch, dtype=torch.long), torch.tensor(movies_batch, dtype=torch.long),
                  torch.tensor(rates_batch, dtype=torch.float)))
users = None
movies = None 
rates = None

class RecommenderNet(nn.Module):
  def __init__(self, n_users, n_movies, n_factors=50, embedding_dropout=0.02, dropout_rate=0.2):
    super().__init__()

    self.u = nn.Embedding(n_users, n_factors)
    self.m = nn.Embedding(n_movies, n_factors)
    self.drop = nn.Dropout(embedding_dropout)
    self.hidden1 = nn.Sequential( 
                nn.Linear(100, 128), 
                nn.ReLU(),
                nn.Dropout(dropout_rate)
        )
    self.hidden2 = nn.Sequential( 
                nn.Linear(128, 256), 
                nn.ReLU(),
                nn.Dropout(dropout_rate)
        )
    self.hidden3 = nn.Sequential( 
                nn.Linear(256, 128), 
                nn.ReLU(),
                nn.Dropout(dropout_rate)
        )
    self.fc = nn.Linear(128, 1)
    self._init()

  def forward(self, users, movies, minmax=[1,4]):
    features = torch.cat([self.u(users), self.m(movies)], dim=1)
    x = self.drop(features)
    x = self.hidden1(x)
    x = self.hidden2(x)
    x = self.hidden3(x)
    out = torch.sigmoid(self.fc(x))
    
    if minmax is not None: #Scale the output to [1,5]
      min_rating, max_rating = minmax
      out = out*(max_rating - min_rating + 1) + min_rating - 0.5
    return out

  def _init(self):
    def init(m):
        if type(m) == nn.Linear:
            torch.nn.init.xavier_uniform_(m.weight)
            m.bias.data.fill_(0.01)

    self.u.weight.data.uniform_(-0.05, 0.05)
    self.m.weight.data.uniform_(-0.05, 0.05)
    self.hidden1.apply(init)
    init(self.fc)

net = RecommenderNet(n_users=n_users, n_movies=n_movies).to(device)
net

criterion = nn.MSELoss(reduction='mean')
optimizer = optim.Adam(net.parameters(), lr=1e-3)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.3, patience=2)

begin_time_computing_nn = time.time()
print(begin_time_computing_nn)
epochs = 10

for epoch in range(epochs):
  train_loss = 0
  for users_batch, movies_batch, rates_batch in batches:
    net.zero_grad()
    out = net(users_batch.to(device), movies_batch.to(device), [1, 4]).squeeze()
    loss = criterion(rates_batch.to(device), out)

    loss.backward()
    optimizer.step()
    train_loss += loss
  scheduler.step(loss)
  print("Loss at epoch {} = {}".format(epoch, loss.item()))
print("Last Loss = {}".format(loss.item())) 

time_computing_nn = time.time() - begin_time_computing_nn
print(time_computing_nn)

import collections
import math
import numpy as np


def predict(model, userId, batches):
  ratings = dict()
  for user_batch, movie_batch, rate_batch in batches:
    out = model(user_batch.to(device)[0:user_batch.shape[0]-1], movie_batch.to(device)[0:movie_batch.shape[0]-1])
    rats = (np.array(out.detach().numpy()))
    for i in range(rats.shape[0]):
      ratings.setdefault(rats[i][0], 0)
      ratings[rats[i][0]] = movie_batch[i].item()
  return collections.OrderedDict(sorted(ratings.items(), reverse=True))

def recommend_movies_nn(model, userId, recommend_num = 10):
  batches_to_predict = []
  unwatched_movies = np.unique(df_ratings_test[df_ratings_test["userId"]!=userId]["movieId"])
  users_array = np.full((unwatched_movies.shape), userId)
  batches_to_predict.append((torch.tensor(users_array, dtype=torch.long), torch.tensor(unwatched_movies, dtype=torch.long), None))
  ratings = predict(model, userId, batches_to_predict)
  array_keys = np.array(ratings.keys())
  res = dict(zip(ratings.values(), [math.floor(x) for x in ratings.keys()]))
  return pd.DataFrame.from_dict(res, orient='index', columns=["Ratings"])[0:recommend_num]


begin_recommend_time_nn = time.time()
print("recomendation for user", df_ratings_test.userId[7000])
print(recommend_movies_nn(net, df_ratings_test.userId[7000], 20))
recommend_time_nn = time.time() - begin_recommend_time_nn
print(recommend_time_nn)

torch.save(net.state_dict(), 'weights')

users = df_ratings['userId'].values - 1
movies = df_ratings['movieId'].values - 1
n_users, n_movies =  max(users)+1, max(movies)+1

model = RecommenderNet(n_users=n_users, n_movies=n_movies).to(device)
model.load_state_dict(torch.load('weights'))
model.eval()